# G2C data
* What is the A and B in the electrode name, does it matter? (Should not matter because otherwise we have more than 60 electrodes)
* But than I only have 59 unique electrodes? ch15 missing? (Yes that is ok thats the one at the bottom)
* What are the differences across the samples with the same age and region? (Started off with the same number every time, but then there are changes in time when the recordings where taken)

# The parameter space exploration issue
* We need so many runs to really explore the parameter space deeply enough as to generate reasonable results?
* We can also look at some first results, such it becomes clearer why we would need to do that
* Currently speed is likely below that of MATLAB
* Should I implement the GNMs in C, alternatively faster cluster
(Will get access to faster cluster during the week, when the C implementation takes more than two days nto worth it)

# Distance measurements
* Could we integrate fiber length? Or how significant would the difference to Euclidean distance be?
(Evolution should ensure that we have kind of direct connections that reassemble euclidean space, but the speed is the more important one)

# Network rules
* Why would you always limit wiring rules to only two nodes? (This would not justify the increase in complexity that comes with it)

# Optimization
* Veronoi tesselation?
* Why not others like simulated annealing? (Could do as potential extension, but more interesting currently is the distance issue)